{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de regresion lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Uriel Antonio Alvarez Chavez 16111783"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a describir paso a paso un ejercicio de prediccion, a travez de la regresion lineal, de la cantidad de ocaciones en que sera compartido un arituculo del area de Machine Learning presentado en un blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccion: Cantidad de ocasiones en que se compartira el articulo del Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos importando librerias, ajustando y visualizando datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm \n",
    "plt.rcParams['figure.figsize'] = (16,9)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import linear_model \n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./articulos de blog ml.csv does not exist: './articulos de blog ml.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7004cc56e16d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# se carga el archivo de datos de entrada csv como dataset de Pandas. los proviene de https://www.knugeets.com\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./articulos de blog ml.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ./articulos de blog ml.csv does not exist: './articulos de blog ml.csv'"
     ]
    }
   ],
   "source": [
    "# se carga el archivo de datos de entrada csv como dataset de Pandas. los proviene de https://www.knugeets.com\n",
    "data = pd.read_csv(\"./articulos de blog ml.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas es una libreria Python destinada al analisis de datos, que proporciona estructuras de datos flexibles que permiten trabjar con ellos de forma eficiente. Pandas ofrece las siguientes estructuras de datos: series: Son arreglos unidemensionales con indexacion (arrays con indice o etiquetados), similar a los diccionarios. Pueden generarse a partir de diccionarios o de listas. Dataframe: son estructuras de datos similares a las tables de base de datos relaciones con SQL. Panel, Panel4d y Panel1ND: Son estructuras de datos que permiten trabjar con mas de dos dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revismaos la dimension (Registros X columnas) que contiene \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se puede revisar los primeros registros para darnos una idea de los datos \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que algunos atributos (columnas) tienen valores nulos(NaN): por ejemplo el atributo url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el atributo Sheres sera la salida, es decir el valor Y del modelo de regresion lineal. Por lo cual sera el valor que deseamos predecir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realiza una estadistica descriptiva para tener conocimiento inicial de los datos mediante:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que, por ejmplo la media del atributo Word count (Cantidad de palabras) es 1808.26 \n",
    "Que el articulo mas pequeño contiene 250 palabras y el mas grande 8401 palabras ¿. \n",
    "Y respecto a cuanto se ha compartido un articulo (#Shares), existe los que nunca se han compartido (0veces) y el o los mas recurrentes con 350000 ocaciones (muy popular!) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización General "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se visualiza los atributos de entrada mediante histogramas y barras (Cuantitativas y cualitativas)\n",
    "data.drop(['Title','url','Elapsed days'],1).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las graficas anteriores comunican entre que valores se concenctran la mayoria de los registros, seguidamente se filtran los datos por cantidad de palabras dejando los registros con menos de 3500 palabras y tambien por cantidad de compartidos con menos a 80. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se puede visualizar por ejemplo cantidad de palabras vs compartidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar datos de entrada \n",
    "colores = ['orange','blue']\n",
    "tamanios = [30,60]\n",
    "\n",
    "f1 = data['Word count'].values\n",
    "f2 = data['# Shares'].values\n",
    "\n",
    "#Pintamos en dos colores los puntos por debajo de la media de cantidad de palabras \n",
    "asignar=[]\n",
    "for index, row in data.iterrows():\n",
    "    if(row['Word count'] > 1808):\n",
    "        asignar.append(colores[0])\n",
    "    else:\n",
    "        asignar.append(colores[1])\n",
    "        \n",
    "plt.scatter(f1, f2, c=asignar, s=tamanios[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZAR los datos en la zona donde se concentran más los puntos\n",
    "# esto es en el eje X: entre 0 y 3.500\n",
    "# y en el eje Y: entre 0 y 80.000\n",
    "filtered_data = data[(data['Word count'] <= 3500) & (data['# Shares'] <= 80000)]\n",
    "\n",
    "f1 = filtered_data['Word count'].values\n",
    "f2 = filtered_data['# Shares'].values\n",
    "\n",
    "# Pintar en colores los puntos por debajo y por encima de la media de Cantidad de Palabras\n",
    "asignar=[]\n",
    "for index, row in filtered_data.iterrows():\n",
    "    if(row['Word count']>1808):\n",
    "        asignar.append(colores[0])\n",
    "    else:\n",
    "        asignar.append(colores[1])\n",
    "    \n",
    "plt.scatter(f1, f2, c=asignar, s=tamanios[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrecion lineal Simple (1 atributo con Python y SKLearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se asigna el atributo de entrada X para entrenamiento y las etiquetas Y \n",
    "dataX=filtered_data[['Word count']]\n",
    "\n",
    "X_train = np.array(dataX)\n",
    "Y_train=filtered_data['# Shares'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se genera el objeto de regresion lineal\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "#se entre el modelo\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "# se realizan las predicciones\n",
    "y_pred = regr.predict(X_train)\n",
    "\n",
    "# se revisa los coeficientes obtenidos, en este caso sera la tangente\n",
    "print('coeficientes: \\n', regr.coef_)\n",
    "# este es el valor donde corta el eje Y (en x=0)\n",
    "print('Termino independiente: \\n', regr.intercept_)\n",
    "# error de cuadrado medio\n",
    "print('Media del error cuadrado %.2f' %mean_squared_error(Y_train, y_pred))\n",
    "# puntaje de varianza. El mejor puntaje es 1.0\n",
    "print('Puntaje de varianza: %2.f' % r2_score(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizacion de la recta obtenida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de la ecuacion de la recta y=mx+b la pendiente \"m\" es el coeficiente 5.69765366 y el termino independiente \"b\" es 11200.303223074163. Existe un error cuadratico grande; por lo cual este modelo no es el mas adecuado. Pero estamos aprendiendo el funcionamiento del algoritmo, lo que resulta imporrtante por el momento. esto lo vemos reflejado en el puntaje de varianza el cual debe ser cerca a 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], Y_train, c=asignar, s=tamanios[0])\n",
    "plt.plot(X_train[:,0], y_pred, color='red', linewidth=3)\n",
    "plt.xlabel('cantidad de palabras')\n",
    "plt.ylabel('cantidad de veces que se compartio')\n",
    "plt.title('Regresion lineal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predecir \n",
    "# cuantos \"shares \" se obtendra por un articulo de 2000 palabras\n",
    "y_dosMil = regr.predict([[2000]])\n",
    "print('cantidad predecida:' , int(y_dosMil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devuelve una prediccion de 25595 \"shares\" para un articulo de 2000 palabras. como podemos mejorar el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se pudiera mejorar el modelo, con una dimension mas\n",
    "# para poder graficar en 3D, se incluye un atributo extra que son la union de enlaces, comentarios e imagenes.\n",
    "union=(filtered_data[\"# of Links\"]+filtered_data['# of comments'].fillna(0)+ filtered_data['# Images video'])\n",
    "dataX2= pd.DataFrame()\n",
    "dataX2[\"Word count\"]= filtered_data[\"Word count\"]\n",
    "dataX2[\"union\"]= union\n",
    "XY_train = np.array(dataX2)\n",
    "z_train= filtered_data['# Shares'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se genera un nuevo objeto de regresion lineal\n",
    "regr2= linear_model.LinearRegression()\n",
    "\n",
    "# se entra el modelo, esta vez, con 2 dimensiones\n",
    "regr2.fit(XY_train, z_train)\n",
    "\n",
    "#se predice con los puntos sobre el plano hallado\n",
    "z_pred = regr2.predict(XY_train)\n",
    "#los coeficientes\n",
    "print('coeficientes: \\n', regr2.coef_)\n",
    "#media del error cuadrado\n",
    "print('MEdia del error cuadrado %.2f' % mean_squared_error(z_train, z_pred))\n",
    "# se evalua el puntaje de varianza (sinedo 1.0 el mejor posible)\n",
    "print ('puntaje de varianza: %.2f' % r2_score(z_train, z_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se vizualiza en 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax= Axes3D(fig)\n",
    "# se genera una malla, sobre la cual se grafica el plano\n",
    "xx, yy= np.meshgrid(np.linspace(0,3500,num =10),np.linspace(0,60, num=10))\n",
    "\n",
    "# se calcua los valores del plano para los puntos x e y\n",
    "nuevoX= (regr2.coef_[0]* xx)\n",
    "nuevoY= (regr2.coef_[1]* yy)\n",
    "\n",
    "# al igual que los correspondientes valores para z. Se debe sumar el punto de intercepcion\n",
    "z= (nuevoX + nuevoY + regr2.intercept_)\n",
    "\n",
    "# se grafica el plano\n",
    "ax.plot_surface(xx,yy,z,alpha=0.2,cmap='hot')\n",
    "\n",
    "# en azul los puntos en 3D\n",
    "ax.scatter(XY_train[:,0], XY_train[:,1], z_train, c='blue', s=30)\n",
    "ax.scatter(XY_train[:,0], XY_train[:,1], z_pred, c='red', s=40)\n",
    "\n",
    "#con esto se situa la camara con la que se visualiza\n",
    "ax.view_init(elev=30., azim=65)\n",
    "ax.set_xlabel('cantidad de palabras')\n",
    "ax.set_ylabel('cantidad de enlaces')\n",
    "ax.set_zlabel('cantidad de veces compartido')\n",
    "ax.set_title('regresion lineal con multiples atributos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede rotar el grafico para apreciar el plano desde diversos angulos, modificando el valor del parametro azim en view_init con numeros del 0 a 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccion 2, modelo de Multiples atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿ que prediccion se tendra para un articulo de 2000 palabras, con 10 enlaces, 4 comentarios y 6 imagenes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantos \"Shares\" se obtendran por un articulo con:\n",
    "# 2000 palabras y con enlaces: 10, comentrios: 4, imagenes: 6\n",
    "# segun el modelo se hace:\n",
    "\n",
    "z_Dosmil = regr2.predict([[2000, 10+4+6]])\n",
    "print('Cantidad predecida : ', int(z_Dosmil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
